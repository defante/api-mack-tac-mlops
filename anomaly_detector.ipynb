{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d40aaa37",
      "metadata": {
        "id": "d40aaa37"
      },
      "source": [
        "### Library and file imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dcceedf1",
      "metadata": {
        "id": "dcceedf1"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8151b5d1",
      "metadata": {
        "id": "8151b5d1"
      },
      "outputs": [],
      "source": [
        "path_to_normal_operation_files = r\"./data/0\"\n",
        "path_to_flow_instability_files = r\"./data/4\"\n",
        "\n",
        "all_normal_operation_files = glob.glob(os.path.join(path_to_normal_operation_files, \"*.csv\"))\n",
        "all_flow_instability_files = glob.glob(os.path.join(path_to_flow_instability_files, \"*.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd04775d",
      "metadata": {
        "id": "dd04775d"
      },
      "source": [
        "### Base samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8eaf4f35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8eaf4f35",
        "outputId": "45b29053-732e-4f4a-ca43-976ad0f8ab38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>P-PDG</th>\n",
              "      <th>P-TPT</th>\n",
              "      <th>T-TPT</th>\n",
              "      <th>P-MON-CKP</th>\n",
              "      <th>T-JUS-CKP</th>\n",
              "      <th>P-JUS-CKGL</th>\n",
              "      <th>T-JUS-CKGL</th>\n",
              "      <th>QGL</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-02-01 02:02:07.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10092110.0</td>\n",
              "      <td>119.0944</td>\n",
              "      <td>1609800.0</td>\n",
              "      <td>84.59782</td>\n",
              "      <td>1564147.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-02-01 02:02:08.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10092000.0</td>\n",
              "      <td>119.0944</td>\n",
              "      <td>1618206.0</td>\n",
              "      <td>84.58997</td>\n",
              "      <td>1564148.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-02-01 02:02:09.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10091890.0</td>\n",
              "      <td>119.0944</td>\n",
              "      <td>1626612.0</td>\n",
              "      <td>84.58213</td>\n",
              "      <td>1564148.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    timestamp  P-PDG       P-TPT     T-TPT  P-MON-CKP  \\\n",
              "0  2017-02-01 02:02:07.000000    0.0  10092110.0  119.0944  1609800.0   \n",
              "1  2017-02-01 02:02:08.000000    0.0  10092000.0  119.0944  1618206.0   \n",
              "2  2017-02-01 02:02:09.000000    0.0  10091890.0  119.0944  1626612.0   \n",
              "\n",
              "   T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  QGL  class  \n",
              "0   84.59782   1564147.0         NaN  0.0    0.0  \n",
              "1   84.58997   1564148.0         NaN  0.0    0.0  \n",
              "2   84.58213   1564148.0         NaN  0.0    0.0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_files = []\n",
        "for filename in all_normal_operation_files:\n",
        "    df_normal = pd.read_csv(filename, index_col=None, header=0)\n",
        "    list_files.append(df_normal)\n",
        "\n",
        "normal_frame = pd.concat(list_files, axis=0)\n",
        "del list_files, df_normal\n",
        "normal_frame.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0a135c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "b0a135c4",
        "outputId": "3db4af52-f726-4351-ea1e-cea1c4b51dfa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>P-PDG</th>\n",
              "      <th>P-TPT</th>\n",
              "      <th>T-TPT</th>\n",
              "      <th>P-MON-CKP</th>\n",
              "      <th>T-JUS-CKP</th>\n",
              "      <th>P-JUS-CKGL</th>\n",
              "      <th>T-JUS-CKGL</th>\n",
              "      <th>QGL</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-03-16 12:02:03.000000</td>\n",
              "      <td>38265830.0</td>\n",
              "      <td>13654450.0</td>\n",
              "      <td>117.1953</td>\n",
              "      <td>6029680.0</td>\n",
              "      <td>68.64587</td>\n",
              "      <td>3283309.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-03-16 12:02:04.000000</td>\n",
              "      <td>38265830.0</td>\n",
              "      <td>13654520.0</td>\n",
              "      <td>117.1947</td>\n",
              "      <td>6030228.0</td>\n",
              "      <td>68.64333</td>\n",
              "      <td>3283309.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-03-16 12:02:05.000000</td>\n",
              "      <td>38265830.0</td>\n",
              "      <td>13654580.0</td>\n",
              "      <td>117.1942</td>\n",
              "      <td>6030777.0</td>\n",
              "      <td>68.64080</td>\n",
              "      <td>3283308.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    timestamp       P-PDG       P-TPT     T-TPT  P-MON-CKP  \\\n",
              "0  2017-03-16 12:02:03.000000  38265830.0  13654450.0  117.1953  6029680.0   \n",
              "1  2017-03-16 12:02:04.000000  38265830.0  13654520.0  117.1947  6030228.0   \n",
              "2  2017-03-16 12:02:05.000000  38265830.0  13654580.0  117.1942  6030777.0   \n",
              "\n",
              "   T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  QGL  class  \n",
              "0   68.64587   3283309.0         NaN  0.0      4  \n",
              "1   68.64333   3283309.0         NaN  0.0      4  \n",
              "2   68.64080   3283308.0         NaN  0.0      4  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_files = []\n",
        "for filename in all_flow_instability_files:\n",
        "    df_anomaly = pd.read_csv(filename, index_col=None, header=0)\n",
        "    list_files.append(df_anomaly)\n",
        "\n",
        "flow_instability_frame = pd.concat(list_files, axis=0)\n",
        "del list_files, df_anomaly\n",
        "flow_instability_frame.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "08c9e6c5",
      "metadata": {
        "id": "08c9e6c5"
      },
      "outputs": [],
      "source": [
        "df_source = pd.concat([normal_frame, flow_instability_frame])\n",
        "del normal_frame, flow_instability_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff153379",
      "metadata": {},
      "source": [
        "### Preprocessing of the whole base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a65b1ea9",
      "metadata": {
        "id": "a65b1ea9"
      },
      "outputs": [],
      "source": [
        "# observations without classification are discarded\n",
        "target_class = 'class'\n",
        "df_pipe = df_source.dropna(subset=[target_class])\n",
        "\n",
        "X_pipe = df_pipe.drop(target_class, axis=1)\n",
        "y_pipe = df_pipe.loc[:, target_class]\n",
        "\n",
        "del df_pipe\n",
        "\n",
        "X_pipe_train, X_pipe_test, y_pipe_train, y_pipe_test = train_test_split(\n",
        "    X_pipe, y_pipe, test_size=0.2, random_state=666\n",
        ")\n",
        "\n",
        "del X_pipe, y_pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c4b5e2",
      "metadata": {
        "id": "66c4b5e2"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "873502de",
      "metadata": {},
      "source": [
        "#### Assembling Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "40f861c8",
      "metadata": {
        "id": "40f861c8"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline, FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8603faf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "8603faf9",
        "outputId": "8c2c74c7-74b9-4010-9c0f-be11a0a70245"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['timestamp', 'T-JUS-CKGL']\n",
        "\n",
        "drop_function = FunctionTransformer(\n",
        "        lambda x: x.drop(columns=columns_to_drop, axis=1)\n",
        ")\n",
        "\n",
        "fill_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "pipe = Pipeline(\n",
        "            steps=[\n",
        "                ('dropout', drop_function),\n",
        "                ('fillna', fill_mean),\n",
        "                ('transform', MinMaxScaler()),\n",
        "                ('clf', GaussianNB()),\n",
        "            ],\n",
        "            verbose=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a646b9",
      "metadata": {},
      "source": [
        "#### Tuning Hyperparameters and Tracking Experiment with MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8f25c217",
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "mlflow.set_experiment(\"mack-tac-experiment\")\n",
        "\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9a96be91",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'imps' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mimps\u001b[49m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'imps' is not defined"
          ]
        }
      ],
      "source": [
        "imps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9913fc64",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting for var_smoothing=1e-09\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=1e-08\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.5s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=1e-07\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.5s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=1e-06\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=1e-05\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.5s\n",
            "Fitting for var_smoothing=0.0001\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.5s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=0.001\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=0.01\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=0.1\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.5s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n",
            "Fitting for var_smoothing=1.0\n",
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.1s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.6s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "Run with UUID 7693004e008c41f9804f3ef47d736411 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mset_tags(\n\u001b[0;32m      3\u001b[0m         {\n\u001b[0;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaussianNB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m             }\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     var_smoothings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m0\u001b[39m, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
            "File \u001b[1;32md:\\Users\\Lucas\\Documents\\workspace\\defante\\api-mack-tac-mlops\\venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:321\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    319\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    322\u001b[0m         (\n\u001b[0;32m    323\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    327\u001b[0m     )\n\u001b[0;32m    328\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
            "\u001b[1;31mException\u001b[0m: Run with UUID 7693004e008c41f9804f3ef47d736411 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
          ]
        }
      ],
      "source": [
        "mlflow.start_run()\n",
        "    mlflow.set_tags(\n",
        "        {\n",
        "            \"model\": \"GaussianNB\",\n",
        "            \"class\": \"experiment\"\n",
        "            }\n",
        "    )\n",
        "    var_smoothings = np.logspace(-9, 0, num=10)\n",
        "    for value in var_smoothings:\n",
        "        mlflow.start_run(nested=True)\n",
        "        print(f\"Fitting for var_smoothing={value}\")\n",
        "        mlflow.log_param('var_smoothing', value)\n",
        "        experiment_pipe = copy.deepcopy(pipe)\n",
        "        experiment_pipe.set_params(clf__var_smoothing=value)\n",
        "        experiment_pipe.fit(X_pipe_train, y_pipe_train)\n",
        "        experiment_predictions = experiment_pipe.predict(X_pipe_test)\n",
        "        mlflow.log_metrics(\n",
        "        {'accuracy': (experiment_pipe.score(X_pipe_test, y_pipe_test)),\n",
        "        'recall': (recall_score(y_pipe_test.values, experiment_predictions, pos_label=4)),\n",
        "        'precision': (precision_score(y_pipe_test.values, experiment_predictions, pos_label=4)),\n",
        "        'f1-score': (f1_score(y_pipe_test.values, experiment_predictions, pos_label=4))\n",
        "        }\n",
        "        )\n",
        "        mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d7e414",
      "metadata": {},
      "source": [
        "#### Metrics of Optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aea9ee15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] ........... (step 1 of 4) Processing dropout, total=   0.2s\n",
            "[Pipeline] ............ (step 2 of 4) Processing fillna, total=   1.5s\n",
            "[Pipeline] ......... (step 3 of 4) Processing transform, total=   0.4s\n",
            "[Pipeline] ............... (step 4 of 4) Processing clf, total=   1.4s\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run():\n",
        "    mlflow.set_tags(\n",
        "        {\n",
        "            \"model\": \"GaussianNB\",\n",
        "            \"class\": \"optimal\"\n",
        "            }\n",
        "    )\n",
        "\n",
        "    optimal_var_smoothing = np.exp(-9)\n",
        "    mlflow.log_param(\"var_smoothing\", optimal_var_smoothing)\n",
        "\n",
        "    pipe.set_params(clf__var_smoothing=optimal_var_smoothing)\n",
        "    pipe.fit(X_pipe_train, y_pipe_train)\n",
        "\n",
        "    predictions = pipe.predict(X_pipe_test)\n",
        "\n",
        "    metrics_data = {\n",
        "        'accuracy': (pipe.score(X_pipe_test, y_pipe_test)),\n",
        "        'recall': (recall_score(y_pipe_test.values, predictions, pos_label=4)),\n",
        "        'precision': (precision_score(y_pipe_test.values, predictions, pos_label=4)),\n",
        "        'f1-score': (f1_score(y_pipe_test.values, predictions, pos_label=4))\n",
        "    }\n",
        "\n",
        "    mlflow.log_metrics(metrics_data)\n",
        "    #mlflow.sklearn.save_model(pipe, \"anomaly_detector_clf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cab8483",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cab8483",
        "outputId": "82cfde76-9494-4b5a-8b40-4fb0c631ab7f"
      },
      "outputs": [],
      "source": [
        "# add confusion matrix\n",
        "metrics_data['cm'] = confusion_matrix(y_pipe_test, predictions)\n",
        "\n",
        "print(metrics_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5814ffb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('results/metrics.txt', 'w') as outfile:\n",
        "    outfile.write(f\"\\nAccuracy = {round(metrics_data['accuracy'], 4)}, \" + \n",
        "                    f\"Recall = {round(metrics_data['recall'], 4)}, \" +\n",
        "                    f\"Precision = {round(metrics_data['precision'], 4)}, \" +\n",
        "                    f\"F1 Score = {round(metrics_data['f1-score'], 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79afc9ac",
      "metadata": {},
      "source": [
        "#### Results Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZYFCWpE072EO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ZYFCWpE072EO",
        "outputId": "13977840-ada2-466f-8aaa-b51a6a779fc7"
      },
      "outputs": [],
      "source": [
        "sns.set_theme()\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
        "\n",
        "sns.heatmap(metrics_data['cm']/np.sum(metrics_data['cm']), annot=True, fmt='.2%', cmap='Blues', ax=axs[0])\n",
        "axs[0].set_xlabel('Predicted Labels')\n",
        "axs[0].set_ylabel('True Labels')\n",
        "axs[0].xaxis.set_ticklabels(['normal', 'anomaly'])\n",
        "axs[0].yaxis.set_ticklabels(['normal', 'anomaly'])\n",
        "axs[0].set_title('Confusion Matrix')\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_pipe_test, predictions, pos_label=4)\n",
        "auc_score = (auc(fpr, tpr))\n",
        "\n",
        "axs[1].plot(fpr, tpr, label=f'(AUC = {auc_score:.2f})', color='red')\n",
        "axs[1].plot([0, 1], [0, 1], color='black', linestyle='--')\n",
        "axs[1].set_xlim([0.0, 1.0])\n",
        "axs[1].set_ylim([0.0, 1.05])\n",
        "axs[1].set_xlabel('False Positive Rate')\n",
        "axs[1].set_ylabel('True Positive Rate')\n",
        "axs[1].set_title(f'ROC Curve')\n",
        "axs[1].legend(loc=\"lower right\")\n",
        "\n",
        "plt.plot()\n",
        "plt.savefig(\"results/model_results.png\", dpi=120)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd7caffd",
      "metadata": {},
      "source": [
        "#### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "acc0aa94",
      "metadata": {},
      "outputs": [],
      "source": [
        "from cloudpickle import dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a948e263",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_file = \"model/anomaly_detector_pipeline.pkl\"\n",
        "\n",
        "with open(model_file, 'wb') as pkl_file:\n",
        "    dump(pipe, pkl_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
